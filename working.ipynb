{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import fileio\n",
    "import keys\n",
    "import full_model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create genre-specific npz files (required for randomizing splits)\n",
    "#fileio.process_data_into_np_files()\n",
    "\n",
    "# To create 27 random splits, each of size 32. (Except the last one, data/working/splits/split_26.npz is only size 5)\n",
    "#fileio.create_random_splits() # Randomized with random.seed(1), so our splits will be identical\n",
    "\n",
    "# To load a range of splits\n",
    "#X, Y = fileio.load_splits(range(5)) # loads splits 0-4\n",
    "#X.shape = (fileio.NUM_SAMPLES_GTZAN, 5 * 32)\n",
    "#Y.shape = (24, 5 * 32)\n",
    "\n",
    "# To generate chroma, aligned with the splits\n",
    "#fileio.generate_chroma_splits_from_splits()\n",
    "\n",
    "# To load a range of chroma splits\n",
    "#X, Y = fileio.load_chroma_splits(range(5)) # loads chroma splits 0-4\n",
    "#X.shape = (300, 12, 5 * 32)\n",
    "#Y.shape = (24, 5 * 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(targets, guesses):\n",
    "    scores = []\n",
    "    \n",
    "    for idx in range(len(targets)):\n",
    "        scores.append(get_score_single(targets[idx], guesses[idx, :]))\n",
    "        \n",
    "    return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_single(target, guess):\n",
    "    scores = keys.get_vector_from_key(target) * 2\n",
    "    return scores[keys.generate_one_hot_guess(guess.data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_torch_data_from_matrices(X, Y):\n",
    "    X = torch.transpose(torch.from_numpy(X), 0, 2)\n",
    "    Y = torch.from_numpy(keys.generate_one_hot_matrix(Y))\n",
    "\n",
    "    X = X.float()\n",
    "    Y = Y.long()\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShallowConvNet(\n",
      "  (conv1): Conv1d(12, 24, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "epoch 0 loss: 3.17764949798584\n",
      "Train accuracy = 0.115625\n",
      "Test accuracy = 0.1964467005076142\n",
      "epoch 100 loss: 2.8103575706481934\n",
      "Train accuracy = 0.599375\n",
      "Test accuracy = 0.56751269035533\n",
      "epoch 200 loss: 2.751507520675659\n",
      "Train accuracy = 0.6296875\n",
      "Test accuracy = 0.6000000000000001\n",
      "epoch 300 loss: 2.7273364067077637\n",
      "Train accuracy = 0.6321875\n",
      "Test accuracy = 0.6055837563451777\n",
      "epoch 400 loss: 2.7117738723754883\n",
      "Train accuracy = 0.64296875\n",
      "Test accuracy = 0.6055837563451777\n",
      "epoch 500 loss: 2.6999459266662598\n",
      "Train accuracy = 0.6537499999999999\n",
      "Test accuracy = 0.6035532994923858\n",
      "epoch 600 loss: 2.691432237625122\n",
      "Train accuracy = 0.65421875\n",
      "Test accuracy = 0.6030456852791878\n",
      "epoch 700 loss: 2.6844308376312256\n",
      "Train accuracy = 0.6576562499999999\n",
      "Test accuracy = 0.6015228426395939\n",
      "epoch 800 loss: 2.678563117980957\n",
      "Train accuracy = 0.66171875\n",
      "Test accuracy = 0.6030456852791878\n",
      "epoch 900 loss: 2.6736202239990234\n",
      "Train accuracy = 0.6671875\n",
      "Test accuracy = 0.6020304568527919\n",
      "epoch 1000 loss: 2.669390916824341\n",
      "Train accuracy = 0.66875\n",
      "Test accuracy = 0.6020304568527919\n",
      "epoch 1100 loss: 2.665708065032959\n",
      "Train accuracy = 0.6684375\n",
      "Test accuracy = 0.6035532994923858\n",
      "epoch 1200 loss: 2.6624882221221924\n",
      "Train accuracy = 0.6678124999999999\n",
      "Test accuracy = 0.6035532994923858\n",
      "epoch 1300 loss: 2.6596322059631348\n",
      "Train accuracy = 0.66765625\n",
      "Test accuracy = 0.6040609137055838\n",
      "epoch 1400 loss: 2.6570961475372314\n",
      "Train accuracy = 0.66921875\n",
      "Test accuracy = 0.6142131979695431\n",
      "epoch 1500 loss: 2.654808282852173\n",
      "Train accuracy = 0.67\n",
      "Test accuracy = 0.6142131979695431\n",
      "epoch 1600 loss: 2.652543783187866\n",
      "Train accuracy = 0.670625\n",
      "Test accuracy = 0.6131979695431473\n",
      "epoch 1700 loss: 2.650437593460083\n",
      "Train accuracy = 0.6709375000000001\n",
      "Test accuracy = 0.6182741116751269\n",
      "epoch 1800 loss: 2.648651599884033\n",
      "Train accuracy = 0.67015625\n",
      "Test accuracy = 0.6182741116751269\n",
      "epoch 1900 loss: 2.6470398902893066\n",
      "Train accuracy = 0.6715625000000001\n",
      "Test accuracy = 0.6182741116751269\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(full_model)\n",
    "\n",
    "net = full_model.ShallowConvNet()\n",
    "print(net)\n",
    "\n",
    "X_test, Y_test = fileio.load_chroma_splits(range(20,27))\n",
    "X_test, Y_test = load_torch_data_from_matrices(X_test, Y_test)\n",
    "\n",
    "X, Y = fileio.load_chroma_splits(range(20))\n",
    "X, Y = load_torch_data_from_matrices(X, Y)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.05)\n",
    "\n",
    "for epoch in range(2000):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    Y_hat = net(X)\n",
    "    loss = criterion(Y_hat, Y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('epoch ' + str(epoch) + ' loss: ' + str(loss.item()))\n",
    "        print('Train accuracy = ' + str(np.mean(get_scores(Y, Y_hat))))\n",
    "        print('Test accuracy = ' + str(np.mean(get_scores(Y_test, net(X_test)))))\n",
    "        \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6703125"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train accuracy\n",
    "np.mean(get_scores(Y, net(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6131979695431473"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test accuracy\n",
    "X, Y = fileio.load_chroma_splits(range(20,27))\n",
    "X, Y = load_torch_data_from_matrices(X, Y)\n",
    "\n",
    "np.mean(get_scores(Y, net(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
