{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython import display\n",
    "\n",
    "import torch\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# local modules\n",
    "import fileio\n",
    "import features\n",
    "import keys\n",
    "import evaluation\n",
    "from utils import grouped_bar_chart, number_countplot\n",
    "\n",
    "FS = fileio.FS\n",
    "NUM_SAMPLES = fileio.NUM_SAMPLES\n",
    "OUTPUT_PREFIX = fileio.OUTPUT_PREFIX  # location of fitted models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['figure.figsize'] = [6.0, 4.0]  # Default\n",
    "mult = 2/3\n",
    "plt.rcParams['figure.figsize'] = [6.0*mult, 4.0*mult]\n",
    "WIDEFIG_SIZE = (10.0*mult, 4.0*mult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data/working'\n",
    "\n",
    "# Full dataset\n",
    "X = np.load(\"{}/X_cqt.npz\".format(DATA_DIR))['X']\n",
    "Y = np.load(\"{}/Y.npz\".format(DATA_DIR))['Y']\n",
    "labels = pd.read_pickle(\"{}/labels.pkl\".format(DATA_DIR))\n",
    "\n",
    "# Indeces for splits\n",
    "with np.load(\"{}/splits.npz\".format(DATA_DIR)) as splits:\n",
    "    train_idx = splits['train_idx']\n",
    "    test_idx = splits['test_idx']\n",
    "\n",
    "# Splits prior to augmentation\n",
    "X_train = X[train_idx, :]\n",
    "Y_train = Y[train_idx, :]\n",
    "labels_train = labels.iloc[train_idx]\n",
    "X_test = X[test_idx, :]\n",
    "Y_test = Y[test_idx, :]\n",
    "labels_test = labels.iloc[test_idx]\n",
    "\n",
    "# The data with which we augment the training data\n",
    "with np.load(\"{}/data_aug.npz\".format(DATA_DIR)) as data:\n",
    "    X_aug = data['X']\n",
    "    Y_aug = data['Y']\n",
    "labels_aug = pd.DataFrame(np.argmax(Y_aug, axis=1), columns=['key'])\n",
    "labels_aug['raw'] = 0.0\n",
    "labels_aug['dataset'] = 'augmented'\n",
    "\n",
    "# Augmented data used for training\n",
    "X_train_aug = np.vstack([X_train, X_aug])\n",
    "Y_train_aug = np.vstack([Y_train, Y_aug])\n",
    "labels_train_aug = pd.concat([labels.iloc[train_idx], labels_aug], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data description:\n",
    "* All imported data (see `fileio` for how these were made):\n",
    "    - `X` - cqt of each waveform\n",
    "    - `Y` - one-hot representation of key for each waveform\n",
    "    - `labels` - key and other labels for each waveform\n",
    "* `train_idx`, `test_idx` - train and test indices for splits (created with `fileio.train_test_split`)\n",
    "* Testing data:\n",
    "    - `*_test`\n",
    "* **Un-augmented** Training data:\n",
    "    - `*_train`\n",
    "* The data which augments the training data:\n",
    "    - `*_aug`\n",
    "* **Augmented** Training data:\n",
    "    - `*_train_aug`\n",
    "    \n",
    "N.B. The test data is not augmented. The augmented training data has the same number of examples for each key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OM1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_torch = torch.from_numpy(X_train_aug).float()\n",
    "X_test_torch = torch.from_numpy(X_test).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pkl_loc = '{}/MO1_model_best.pkl'.format(OUTPUT_PREFIX)\n",
    "mdl = torch.load(model_pkl_loc).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "X_torch = X_train_torch\n",
    "nr_obs = X_torch.shape[0]\n",
    "num_batches = int(np.ceil(nr_obs / batch_size))\n",
    "pred_prob_train = []\n",
    "for batch_num in range(num_batches):\n",
    "    from_idx = batch_size * batch_num\n",
    "    to_idx = min(batch_size * (batch_num+1), nr_obs)\n",
    "    X_batch = X_torch[from_idx:to_idx]\n",
    "    X_batch = X_batch.to(device)\n",
    "    pred = mdl(X_batch).to('cpu')\n",
    "    pred_prob_train += [pred.detach().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_train = np.vstack(pred_prob_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "X_torch = X_test_torch\n",
    "nr_obs = X_torch.shape[0]\n",
    "num_batches = int(np.ceil(nr_obs / batch_size))\n",
    "pred_prob_test = []\n",
    "for batch_num in range(num_batches):\n",
    "    from_idx = batch_size * batch_num\n",
    "    to_idx = min(batch_size * (batch_num+1), nr_obs)\n",
    "    X_batch = X_torch[from_idx:to_idx]\n",
    "    X_batch = X_batch.to(device)\n",
    "    pred = mdl(X_batch).to('cpu')\n",
    "    pred_prob_test += [pred.detach().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_test = np.vstack(pred_prob_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs['OM1'] = {'train': pred_prob_train, 'test': pred_prob_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OM2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pkl_loc = '{}/MO2_model_best.pkl'.format(OUTPUT_PREFIX)\n",
    "mdl = torch.load(model_pkl_loc).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "X_torch = X_train_torch\n",
    "nr_obs = X_torch.shape[0]\n",
    "num_batches = int(np.ceil(nr_obs / batch_size))\n",
    "pred_prob_train = []\n",
    "for batch_num in range(num_batches):\n",
    "    from_idx = batch_size * batch_num\n",
    "    to_idx = min(batch_size * (batch_num+1), nr_obs)\n",
    "    X_batch = X_torch[from_idx:to_idx]\n",
    "    X_batch = X_batch.to(device)\n",
    "    pred = mdl(X_batch).to('cpu')\n",
    "    pred_prob_train += [pred.detach().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_train = np.vstack(pred_prob_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "X_torch = X_test_torch\n",
    "nr_obs = X_torch.shape[0]\n",
    "num_batches = int(np.ceil(nr_obs / batch_size))\n",
    "pred_prob_test = []\n",
    "for batch_num in range(num_batches):\n",
    "    from_idx = batch_size * batch_num\n",
    "    to_idx = min(batch_size * (batch_num+1), nr_obs)\n",
    "    X_batch = X_torch[from_idx:to_idx]\n",
    "    X_batch = X_batch.to(device)\n",
    "    pred = mdl(X_batch).to('cpu')\n",
    "    pred_prob_test += [pred.detach().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_test = np.vstack(pred_prob_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs['OM2'] = {'train': pred_prob_train, 'test': pred_prob_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OM3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_aug_mean = np.mean(X_train_aug, axis=2)\n",
    "X_train_aug_mean -= np.mean(X_train_aug_mean, axis=1, keepdims=True)\n",
    "\n",
    "X_test_mean = np.mean(X_test, axis=2)\n",
    "X_test_mean -= np.mean(X_test_mean, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pkl_loc = '{}/MO3_model_best.pkl'.format(OUTPUT_PREFIX)\n",
    "mdl = joblib.load(model_pkl_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_train = mdl.predict_proba(X_train_aug_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_test = mdl.predict_proba(X_test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_prob_train.shape, pred_prob_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs['OM3'] = {'train': pred_prob_train, 'test': pred_prob_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(pred_prob_train, pred_prob_test, Y_train, Y_test, labels_train, labels_test):\n",
    "    y_train = np.argmax(Y_train, axis=1)\n",
    "    y_test = np.argmax(Y_test, axis=1)\n",
    "    pred_train = np.argmax(pred_prob_train, axis=1)\n",
    "    pred_test = np.argmax(pred_prob_test, axis=1)\n",
    "    \n",
    "#     # Maybe adapt this to do train vs test pred prob quality comparison\n",
    "#     plt.figure()\n",
    "#     grouped_bar_chart(np.mean((Y_test - pred_prob_test)**2, axis=0, keepdims=True))\n",
    "    \n",
    "    plt.figure()\n",
    "    evaluation.plot_confusion_matrix(y_train, pred_train, title='Train', norm=True, annot=False)\n",
    "    \n",
    "    plt.figure()\n",
    "    evaluation.plot_confusion_matrix(y_test, pred_test, title='Test', norm=True, annot=False)\n",
    "    \n",
    "    scores_train = evaluation.get_scores(y_train, pred_train)\n",
    "    plt.figure()\n",
    "    plt.title('Train scores. Avg = {:.3f}'.format(np.mean(scores_train)))\n",
    "    sns.countplot(scores_train)\n",
    "    number_countplot()\n",
    "    \n",
    "    scores_test = evaluation.get_scores(y_test, pred_test)\n",
    "    plt.figure()\n",
    "    plt.title('Test scores. Avg = {:.3f}'.format(np.mean(scores_test)))\n",
    "    sns.countplot(scores_test)\n",
    "    number_countplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
